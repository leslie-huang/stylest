<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Leslie Huang" />

<meta name="date" content="2018-09-17" />

<title>stylest vignette</title>

<script src="data:application/x-javascript;base64,JChkb2N1bWVudCkucmVhZHkoZnVuY3Rpb24oKXsKICAgICQoJ1tkYXRhLXRvZ2dsZT0idG9vbHRpcCJdJykudG9vbHRpcCgpOwogICAgJCgnW2RhdGEtdG9nZ2xlPSJwb3BvdmVyIl0nKS5wb3BvdmVyKCk7Cn0pOwo="></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">stylest vignette</h1>
<h4 class="author"><em>Leslie Huang</em></h4>
<h4 class="date"><em>2018-09-17</em></h4>



<div id="about-stylest" class="section level1">
<h1>About <code>stylest</code></h1>
<p>This vignette describes the usage of <code>stylest</code> for estimating speaker (author) style distinctiveness.</p>
<div id="installation" class="section level3">
<h3>Installation</h3>
<p>Install <code>stylest</code> from CRAN by executing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;stylest&quot;</span>)</code></pre></div>
<p>The dev version of <code>stylest</code> on GitHub may have additional features (and bugs) and is not guaranteed to be stable. Power users may install it with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;devtools&quot;)</span>
<span class="co"># devtools::install_github(&quot;leslie-huang/stylest&quot;)</span></code></pre></div>
</div>
<div id="load-the-package" class="section level3">
<h3>Load the package</h3>
<p><code>stylest</code> is built on top of <code>corpus</code>. <code>corpus</code> is required to specify (optional) parameters in <code>stylest</code>, so we recommend installing <code>corpus</code> as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stylest)
<span class="kw">library</span>(corpus)</code></pre></div>
</div>
</div>
<div id="example-fitting-a-model-to-english-novels" class="section level1">
<h1>Example: Fitting a model to English novels</h1>
<div id="corpus" class="section level2">
<h2>Corpus</h2>
<p>We will be using texts of the first lines of novels by Jane Austen, George Eliot, and Elizabeth Gaskell. Excerpts were obtained from the full texts of novels available on Project Gutenberg: <a href="http://gutenberg.org" class="uri">http://gutenberg.org</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(novels_excerpts)</code></pre></div>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
title
</th>
<th style="text-align:left;">
author
</th>
<th style="text-align:left;">
text
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
A Dark Night’s Work
</td>
<td style="text-align:left;">
Gaskell, Elizabeth Cleghorn
</td>
<td style="text-align:left;">
In the county town of a certain shire there lived (about forty years ago) one Mr. Wilkins, a conveyancing attorney of considerable standing. The certain shire was but a small county, and the principal town in it contained only about four thousand inhabitants; so in saying that Mr. Wilkins was the principal lawyer in Hamley, I say very little, unless I add that he transacted all the legal business of the gentry for twenty miles round. His grandfather had established the connection; his father had consolidated and strengthened it, and, indeed, by his wise and upright conduct, as well as by his professional skill, had obtained for himself the position of confidential friend to many of the surrounding families of distinction.
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
Brother Jacob
</td>
<td style="text-align:left;">
Eliot, George
</td>
<td style="text-align:left;">
Among the many fatalities attending the bloom of young desire, that of blindly taking to the confectionery line has not, perhaps, been sufficiently considered. How is the son of a British yeoman, who has been fed principally on salt pork and yeast dumplings, to know that there is satiety for the human stomach even in a paradise of glass jars full of sugared almonds and pink lozenges, and that the tedium of life can reach a pitch where plum-buns at discretion cease to offer the slightest excitement? Or how, at the tender age when a confectioner seems to him a very prince whom all the world must envy–who breakfasts on macaroons, dines on meringues, sups on twelfth-cake, and fills up the intermediate hours with sugar-candy or peppermint–how is he to foresee the day of sad wisdom, when he will discern that the confectioner’s calling is not socially influential, or favourable to a soaring ambition?
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
Emma
</td>
<td style="text-align:left;">
Austen, Jane
</td>
<td style="text-align:left;">
Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her. She was the youngest of the two daughters of a most affectionate, indulgent father; and had, in consequence of her sister’s marriage, been mistress of his house from a very early period. Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses; and her place had been supplied by an excellent woman as governess, who had fallen little short of a mother in affection. Sixteen years had Miss Taylor been in Mr. Woodhouse’s family, less as a governess than a friend, very fond of both daughters, but particularly of Emma. Between <em>them</em> it was more the intimacy of sisters.
</td>
</tr>
</tbody>
</table>
<p>The corpus should have at least one variable by which the texts can be grouped — the most common examples are a “speaker” or “author” attribute. Here, we will use <code>novels_excerpts$author</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unique</span>(novels_excerpts<span class="op">$</span>author)
<span class="co">#&gt; [1] &quot;Gaskell, Elizabeth Cleghorn&quot; &quot;Eliot, George&quot;              </span>
<span class="co">#&gt; [3] &quot;Austen, Jane&quot;</span></code></pre></div>
</div>
<div id="using-stylest_select_vocab" class="section level2">
<h2>Using <code>stylest_select_vocab</code></h2>
<p>This function uses n-fold cross-validation to identify the set of terms that maximizes the model’s rate of predicting the speakers of out-of-sample texts. For those unfamiliar with cross-validation, the technical details follow:</p>
<ul>
<li>The terms of the raw vocabulary are ordered by frequency.</li>
<li>A subset of the raw vocabulary above a frequency percentile is selected; e.g. terms above the 50th percentile are those which occur more frequently than the median term in the raw vocabulary.</li>
<li>The corpus is divided into n folds.</li>
<li>One of these folds is held out and the model is fit using the remaining n-1 folds. The model is then used to predict the speakers of texts in the held-out fold. (This step is repeated n times.)</li>
<li>The mean prediction rate for models using this vocabulary (percentile) is calculated.</li>
</ul>
<p>(Vocabulary selection is optional; the model can be fit using all the terms in the support of the corpus.)</p>
<p>Setting the seed before this step, to ensure reproducible runs, is recommended:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</code></pre></div>
<p>Below are examples of <code>stylest_select_vocab</code> using the defaults and with custom parameters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vocab_with_defaults &lt;-<span class="st"> </span><span class="kw">stylest_select_vocab</span>(novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author)</code></pre></div>
<p>Tokenization selections can optionally be passed as the <code>filter</code> argument; see the <code>corpus</code> package for more information about <code>text_filter</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">filter &lt;-<span class="st"> </span>corpus<span class="op">::</span><span class="kw">text_filter</span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>, <span class="dt">drop_number =</span> <span class="ot">TRUE</span>)

vocab_custom &lt;-<span class="st"> </span><span class="kw">stylest_select_vocab</span>(novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author, 
                                     <span class="dt">filter =</span> filter, <span class="dt">smooth =</span> <span class="dv">1</span>, <span class="dt">nfold =</span> <span class="dv">10</span>, 
                                     <span class="dt">cutoff_pcts =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">75</span>, <span class="dv">99</span>))</code></pre></div>
<p>Let’s look inside the <code>vocab_with_defaults</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Percentile with best prediction rate</span>
vocab_with_defaults<span class="op">$</span>cutoff_pct_best
<span class="co">#&gt; [1] 80</span>

<span class="co"># Rate of INCORRECTLY predicted speakers of held-out texts</span>
vocab_with_defaults<span class="op">$</span>miss_pct
<span class="co">#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]</span>
<span class="co">#&gt; [1,] 25.00000 25.00000 25.00000  0.00000 50.00000 50.00000</span>
<span class="co">#&gt; [2,] 75.00000 75.00000 75.00000 75.00000 75.00000 75.00000</span>
<span class="co">#&gt; [3,] 66.66667 66.66667 66.66667 33.33333 33.33333 33.33333</span>
<span class="co">#&gt; [4,] 20.00000 20.00000 20.00000 20.00000 40.00000 40.00000</span>
<span class="co">#&gt; [5,] 80.00000 80.00000 80.00000 60.00000 40.00000 20.00000</span>

<span class="co"># Data on the setup:</span>

<span class="co"># Percentiles tested</span>
vocab_with_defaults<span class="op">$</span>cutoff_pcts
<span class="co">#&gt; [1] 50 60 70 80 90 99</span>

<span class="co"># Number of folds</span>
vocab_with_defaults<span class="op">$</span>nfold
<span class="co">#&gt; [1] 5</span></code></pre></div>
</div>
<div id="fitting-a-model" class="section level2">
<h2>Fitting a model</h2>
<div id="using-a-percentile-to-select-terms" class="section level3">
<h3>Using a percentile to select terms</h3>
<p>With the best percentile identified as 80 percent, we can select the terms above that percentile to use in the model. Be sure to use the same <code>text_filter</code> here as in the previous step.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">terms_<span class="dv">80</span> &lt;-<span class="st"> </span><span class="kw">stylest_terms</span>(novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author, <span class="dv">80</span>, <span class="dt">filter =</span> filter)</code></pre></div>
</div>
<div id="fitting-the-model" class="section level3">
<h3>Fitting the model</h3>
<p>Below, we fit the model using the terms above the 80th percentile, using the same <code>text_filter</code> as before, and leaving the smoothing value for term frequencies as the default <code>0.5</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
mod &lt;-<span class="st"> </span><span class="kw">stylest_fit</span>(novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author, <span class="dt">terms =</span> terms_<span class="dv">80</span>, <span class="dt">filter =</span> filter)</code></pre></div>
<p>The model contains detailed information about token usage by each of the authors; exploring this is left as an exercise.</p>
</div>
</div>
<div id="using-the-model" class="section level2">
<h2>Using the model</h2>
<div id="calculating-speaker-log-odds" class="section level3">
<h3>Calculating speaker log odds</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
odds &lt;-<span class="st"> </span><span class="kw">stylest_odds</span>(mod, novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author)</code></pre></div>
<p>We can examine the mean log odds that Jane Austen wrote <em>Pride and Prejudice</em> (in-sample).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pride and Prejudice</span>
novels_excerpts<span class="op">$</span>text[<span class="dv">14</span>]
<span class="co">#&gt; [1] &quot;It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. \&quot;My dear Mr. Bennet,\&quot; said his lady to him one day, \&quot;have you heard that Netherfield Park is let at last?\&quot; Mr. Bennet replied that he had not. \&quot;But it is,\&quot; returned she; \&quot;for Mrs. Long has just been here, and she told me all about it.\&quot; Mr. Bennet made no answer. \&quot;Do you not want to know who has taken it?\&quot; cried his wife impatiently. \&quot;_You_ want to tell me, and I have no objection to hearing it.\&quot; This was invitation enough.&quot;</span>

odds<span class="op">$</span>log_odds_avg[<span class="dv">14</span>]
<span class="co">#&gt; [1] 0.2491968</span>

odds<span class="op">$</span>log_odds_se[<span class="dv">14</span>]
<span class="co">#&gt; [1] 0.1290187</span></code></pre></div>
</div>
<div id="predicting-the-speaker-of-a-new-text" class="section level3">
<h3>Predicting the speaker of a new text</h3>
<p>In this example, the model is used to predict the speaker of a new text, in this case <em>Northanger Abbey</em> by Jane Austen.</p>
<p>Note that a <code>prior</code> may be specified, and may be useful for handling texts containing out-of-sample terms. Here, we do not specify a prior, so a uniform prior is used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
na_text &lt;-<span class="st"> &quot;No one who had ever seen Catherine Morland in her infancy would have supposed </span>
<span class="st">            her born to be an heroine. Her situation in life, the character of her father </span>
<span class="st">            and mother, her own person and disposition, were all equally against her. Her </span>
<span class="st">            father was a clergyman, without being neglected, or poor, and a very respectable </span>
<span class="st">            man, though his name was Richard—and he had never been handsome. He had a </span>
<span class="st">            considerable independence besides two good livings—and he was not in the least </span>
<span class="st">            addicted to locking up his daughters.&quot;</span>

pred &lt;-<span class="st"> </span><span class="kw">stylest_predict</span>(mod, na_text)</code></pre></div>
<p>Viewing the result, and recovering the log probabilities calculated for each speaker, is simple:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred<span class="op">$</span>predicted
<span class="co">#&gt; [1] Austen, Jane</span>
<span class="co">#&gt; Levels: Austen, Jane Eliot, George Gaskell, Elizabeth Cleghorn</span>

pred<span class="op">$</span>log_probs
<span class="co">#&gt; 1 x 3 Matrix of class &quot;dgeMatrix&quot;</span>
<span class="co">#&gt;      Austen, Jane Eliot, George Gaskell, Elizabeth Cleghorn</span>
<span class="co">#&gt; [1,]  -1.1956e-05     -42.61985                   -11.33428</span></code></pre></div>
</div>
<div id="influential-terms" class="section level3">
<h3>Influential terms</h3>
<p><code>stylest_term_influence</code> identifies terms’ contributions to speakers’ distinctiveness in a fitted model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
influential_terms &lt;-<span class="st"> </span><span class="kw">stylest_term_influence</span>(mod, novels_excerpts<span class="op">$</span>text, novels_excerpts<span class="op">$</span>author)</code></pre></div>
<p>The mean and maximum influence can be accessed with <code>$infl_avg</code> and <code>$infl_max</code>, respectively.</p>
<p>The terms with the highest mean influence can be obtained:</p>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
infl_avg
</th>
<th style="text-align:right;">
infl_max
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
the
</td>
<td style="text-align:right;">
3.1276856
</td>
<td style="text-align:right;">
5.943936
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
of
</td>
<td style="text-align:right;">
1.2237994
</td>
<td style="text-align:right;">
1.624485
</td>
</tr>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
i
</td>
<td style="text-align:right;">
1.1128586
</td>
<td style="text-align:right;">
2.445026
</td>
</tr>
<tr>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
was
</td>
<td style="text-align:right;">
0.9560661
</td>
<td style="text-align:right;">
2.513274
</td>
</tr>
<tr>
<td style="text-align:left;">
36
</td>
<td style="text-align:left;">
her
</td>
<td style="text-align:right;">
0.8214846
</td>
<td style="text-align:right;">
2.276707
</td>
</tr>
<tr>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
on
</td>
<td style="text-align:right;">
0.8014783
</td>
<td style="text-align:right;">
1.868317
</td>
</tr>
</tbody>
</table>
<p>And the least influential terms:</p>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
infl_avg
</th>
<th style="text-align:right;">
infl_max
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
249
</td>
<td style="text-align:left;">
taken
</td>
<td style="text-align:right;">
0.0213342
</td>
<td style="text-align:right;">
0.0621163
</td>
</tr>
<tr>
<td style="text-align:left;">
252
</td>
<td style="text-align:left;">
thought
</td>
<td style="text-align:right;">
0.0213342
</td>
<td style="text-align:right;">
0.0621163
</td>
</tr>
<tr>
<td style="text-align:left;">
254
</td>
<td style="text-align:left;">
turned
</td>
<td style="text-align:right;">
0.0213342
</td>
<td style="text-align:right;">
0.0621163
</td>
</tr>
<tr>
<td style="text-align:left;">
259
</td>
<td style="text-align:left;">
whose
</td>
<td style="text-align:right;">
0.0213342
</td>
<td style="text-align:right;">
0.0621163
</td>
</tr>
<tr>
<td style="text-align:left;">
260
</td>
<td style="text-align:left;">
woman
</td>
<td style="text-align:right;">
0.0213342
</td>
<td style="text-align:right;">
0.0621163
</td>
</tr>
<tr>
<td style="text-align:left;">
33
</td>
<td style="text-align:left;">
from
</td>
<td style="text-align:right;">
0.0111362
</td>
<td style="text-align:right;">
0.0168330
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="issues" class="section level2">
<h2>Issues</h2>
<p>Please submit any bugs, error reports, etc. on GitHub at: <a href="https://github.com/leslie-huang/stylest/issues" class="uri">https://github.com/leslie-huang/stylest/issues</a>.</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
